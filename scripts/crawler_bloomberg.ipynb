{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df81ce28-b57c-4b3d-b5a8-828f9da8d361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ•·ï¸  Bloomberg Economics Scraper - Enhanced Human-like Version\n",
      "======================================================================\n",
      "â±ï¸  Runtime: 00:16:52\n",
      "ðŸŽ¯  Current Phase: Completion\n",
      "ðŸ”„  Clicks Completed: 51\n",
      "ðŸ“Š  Total Articles: 494\n",
      "ðŸ”—  Consecutive Clicks: 4\n",
      "======================================================================\n",
      "ðŸ“  Current Action: Scraping completed! Final: 494 articles after 51 clicks âœ…\n",
      "======================================================================\n",
      "ðŸ“ˆ  Avg Articles/Click: 9.7\n",
      "âš¡  Performance: 3.0 clicks/minute\n",
      "\n",
      "ðŸ’» Environment: Jupyter Notebook\n",
      "ðŸ’¡ Tip: The scraper is running human-like behaviors to avoid detection\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from playwright.async_api import async_playwright\n",
    "import json\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "\n",
    "try:\n",
    "    from IPython.display import clear_output\n",
    "    IN_NOTEBOOK = True\n",
    "except ImportError:\n",
    "    IN_NOTEBOOK = False\n",
    "\n",
    "class ScraperStatus:\n",
    "    def __init__(self):\n",
    "        self.start_time = time.time()\n",
    "        self.current_click = 0\n",
    "        self.total_articles = 0\n",
    "        self.last_action = \"Starting...\"\n",
    "        self.current_phase = \"Initialization\"\n",
    "        self.consecutive_clicks = 0\n",
    "        \n",
    "    def update(self, action=None, phase=None, click=None, articles=None, consecutive=None):\n",
    "        if action:\n",
    "            self.last_action = action\n",
    "        if phase:\n",
    "            self.current_phase = phase\n",
    "        if click is not None:\n",
    "            self.current_click = click\n",
    "        if articles is not None:\n",
    "            self.total_articles = articles\n",
    "        if consecutive is not None:\n",
    "            self.consecutive_clicks = consecutive\n",
    "        self.display()\n",
    "    \n",
    "    def display(self):\n",
    "        if IN_NOTEBOOK:\n",
    "            clear_output(wait=True)\n",
    "        else:\n",
    "            os.system('cls' if os.name == 'nt' else 'clear')\n",
    "        \n",
    "        runtime = time.time() - self.start_time\n",
    "        hours, remainder = divmod(runtime, 3600)\n",
    "        minutes, seconds = divmod(remainder, 60)\n",
    "        \n",
    "        print(\"ðŸ•·ï¸  Bloomberg Economics Scraper - Enhanced Human-like Version\")\n",
    "        print(\"=\" * 70)\n",
    "        print(f\"â±ï¸  Runtime: {int(hours):02d}:{int(minutes):02d}:{int(seconds):02d}\")\n",
    "        print(f\"ðŸŽ¯  Current Phase: {self.current_phase}\")\n",
    "        print(f\"ðŸ”„  Clicks Completed: {self.current_click}\")\n",
    "        print(f\"ðŸ“Š  Total Articles: {self.total_articles}\")\n",
    "        print(f\"ðŸ”—  Consecutive Clicks: {self.consecutive_clicks}\")\n",
    "        print(\"=\" * 70)\n",
    "        print(f\"ðŸ“  Current Action: {self.last_action}\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        if self.current_click > 0:\n",
    "            avg_articles_per_click = self.total_articles / self.current_click if self.current_click > 0 else 0\n",
    "            print(f\"Avg Articles/Click: {avg_articles_per_click:.1f}\")\n",
    "            print(f\"Performance: {self.current_click/(runtime/60):.1f} clicks/minute\")\n",
    "        \n",
    "        environment = \"Jupyter Notebook\" if IN_NOTEBOOK else \"Terminal\"\n",
    "        print(f\"\\nEnvironment: {environment}\")\n",
    "        print(\"ðŸ’¡ Tip: The scraper is running human-like behaviors to avoid detection\")\n",
    "        if not IN_NOTEBOOK:\n",
    "            print(\"Press Ctrl+C to stop gracefully\")\n",
    "        print()\n",
    "\n",
    "def log_action(status, action, phase=None):\n",
    "    \"\"\"æ›´æ–°å¹¶æ˜¾ç¤ºå½“å‰åŠ¨ä½œ\"\"\"\n",
    "    status.update(action=action, phase=phase)\n",
    "\n",
    "def log_progress(status, click, articles, action=\"Progress Update\"):\n",
    "    \"\"\"æ›´æ–°å¹¶æ˜¾ç¤ºè¿›åº¦\"\"\"\n",
    "    status.update(action=action, click=click, articles=articles)\n",
    "\n",
    "async def human_like_mouse_movement(page, target_x, target_y, current_x=None, current_y=None):\n",
    "    \"\"\"æ›´æ‹Ÿäººçš„é¼ æ ‡ç§»åŠ¨è·¯å¾„\"\"\"\n",
    "    if current_x is None or current_y is None:\n",
    "        current_x = random.randint(200, 800)\n",
    "        current_y = random.randint(200, 600)\n",
    "\n",
    "    distance = ((target_x - current_x) ** 2 + (target_y - current_y) ** 2) ** 0.5\n",
    "\n",
    "    if distance > 200:\n",
    "        mid_x = current_x + (target_x - current_x) * 0.6 + random.randint(-50, 50)\n",
    "        mid_y = current_y + (target_y - current_y) * 0.6 + random.randint(-30, 30)\n",
    "        \n",
    "        await page.mouse.move(mid_x, mid_y, steps=random.randint(15, 25))\n",
    "        await page.wait_for_timeout(random.randint(100, 300))\n",
    "        await page.mouse.move(target_x, target_y, steps=random.randint(10, 20))\n",
    "    else:\n",
    "        steps = max(5, int(distance / 10))\n",
    "        await page.mouse.move(target_x, target_y, steps=steps)\n",
    "\n",
    "async def simulate_reading_behavior(page):\n",
    "    \"\"\"æ¨¡æ‹ŸçœŸå®žçš„é˜…è¯»å’Œæµè§ˆè¡Œä¸º - ä¼˜åŒ–ç‰ˆ\"\"\"\n",
    "    behaviors = [\n",
    "        'scroll_down',\n",
    "        'scroll_up', \n",
    "        'hover_article',\n",
    "        'quick_scan',\n",
    "        'pause_thinking'\n",
    "    ]\n",
    "    \n",
    "    selected_behaviors = random.sample(behaviors, random.randint(1, 2))\n",
    "    \n",
    "    for behavior in selected_behaviors:\n",
    "        if behavior == 'scroll_down':\n",
    "            for _ in range(random.randint(1, 2)):\n",
    "                await page.mouse.wheel(0, random.randint(150, 300))\n",
    "                await page.wait_for_timeout(random.randint(300, 800))  \n",
    "                \n",
    "        elif behavior == 'scroll_up':\n",
    "            await page.mouse.wheel(0, random.randint(-400, -200))\n",
    "            await page.wait_for_timeout(random.randint(400, 1000))  \n",
    "            \n",
    "        elif behavior == 'hover_article':\n",
    "            await hover_on_random_article(page)\n",
    "            \n",
    "        elif behavior == 'quick_scan':\n",
    "            await quick_scan_page(page)\n",
    "            \n",
    "        elif behavior == 'pause_thinking':\n",
    "            await page.wait_for_timeout(random.randint(1000, 2500))\n",
    "        \n",
    "        await page.wait_for_timeout(random.randint(200, 500))\n",
    "\n",
    "async def hover_on_random_article(page):\n",
    "    \"\"\"éšæœºæ‚¬åœåœ¨æ–‡ç« æ ‡é¢˜ä¸Šï¼Œæ¨¡æ‹Ÿé˜…è¯» - ä¼˜åŒ–ç‰ˆ\"\"\"\n",
    "    try:\n",
    "        articles = await page.query_selector_all('section#archive_story_list a')\n",
    "        if articles:\n",
    "            article = random.choice(articles[-10:])\n",
    "            box = await article.bounding_box()\n",
    "            if box:\n",
    "                x = box['x'] + box['width'] / 2\n",
    "                y = box['y'] + box['height'] / 2\n",
    "                await human_like_mouse_movement(page, x, y)\n",
    "                await page.wait_for_timeout(random.randint(800, 1500))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "async def quick_scan_page(page):\n",
    "    for _ in range(random.randint(2, 4)):\n",
    "        x = random.randint(200, 1000)\n",
    "        y = random.randint(300, 700)\n",
    "        await page.mouse.move(x, y, steps=random.randint(5, 12))\n",
    "        await page.wait_for_timeout(random.randint(200, 600))  \n",
    "\n",
    "async def random_mouse_movements(page):\n",
    "    \"\"\"éšæœºé¼ æ ‡ç§»åŠ¨ - ä¼˜åŒ–ç‰ˆ\"\"\"\n",
    "    movements = random.randint(2, 4)  \n",
    "    for _ in range(movements):\n",
    "        x = random.randint(100, 1200)\n",
    "        y = random.randint(200, 800)\n",
    "        await human_like_mouse_movement(page, x, y)\n",
    "        await page.wait_for_timeout(random.randint(200, 500))  \n",
    "\n",
    "async def check_page_sections(page):\n",
    "    \"\"\"æ£€æŸ¥é¡µé¢ä¸åŒåŒºåŸŸ - ä¼˜åŒ–ç‰ˆ\"\"\"\n",
    "    sections = [\n",
    "        (200, 100),   \n",
    "        (1000, 300),  \n",
    "        (150, 500),   \n",
    "    ]\n",
    "    \n",
    "    section = random.choice(sections)\n",
    "    x, y = section\n",
    "    await human_like_mouse_movement(page, x, y)\n",
    "    await page.wait_for_timeout(random.randint(500, 1000))  \n",
    "\n",
    "async def simulate_headline_reading(page):\n",
    "    \"\"\"æ¨¡æ‹Ÿæ ‡é¢˜é˜…è¯» - ä¼˜åŒ–ç‰ˆ\"\"\"\n",
    "    try:\n",
    "        headlines = await page.query_selector_all('h1, h2, h3, .headline')\n",
    "        if headlines:\n",
    "            headline = random.choice(headlines[:5])\n",
    "            box = await headline.bounding_box()\n",
    "            if box:\n",
    "                await human_like_mouse_movement(page, box['x'] + 10, box['y'] + box['height']/2)\n",
    "                await page.wait_for_timeout(random.randint(800, 1500))  \n",
    "    except:\n",
    "        pass\n",
    "\n",
    "async def simulate_human_click_preparation(page, button):\n",
    "    \"\"\"ç‚¹å‡»å‰çš„æ‹ŸäººåŒ–å‡†å¤‡åŠ¨ä½œ - ä¼˜åŒ–ç‰ˆ\"\"\"\n",
    "    await simulate_reading_behavior(page)\n",
    "    \n",
    "    await button.scroll_into_view_if_needed()\n",
    "    await page.wait_for_timeout(random.randint(500, 1000))  \n",
    "    \n",
    "    box = await button.bounding_box()\n",
    "    if not box:\n",
    "        return False\n",
    "    \n",
    "    button_x = box['x'] + box['width'] / 2\n",
    "    button_y = box['y'] + box['height'] / 2\n",
    "    \n",
    "    search_areas = [\n",
    "        (button_x + random.randint(-100, 100), button_y + random.randint(-50, 50)),\n",
    "        (button_x + random.randint(-50, 50), button_y + random.randint(-25, 25)),\n",
    "    ]\n",
    "    \n",
    "    for search_x, search_y in search_areas:\n",
    "        await human_like_mouse_movement(page, search_x, search_y)\n",
    "        await page.wait_for_timeout(random.randint(300, 600))  \n",
    "    \n",
    "    await human_like_mouse_movement(page, button_x, button_y, search_areas[-1][0], search_areas[-1][1])\n",
    "    \n",
    "    await page.wait_for_timeout(random.randint(400, 800))  \n",
    "    \n",
    "    return True, button_x, button_y\n",
    "\n",
    "async def perform_human_like_click(page, x, y):\n",
    "    \"\"\"æ‰§è¡Œæ‹ŸäººåŒ–çš„ç‚¹å‡»\"\"\"\n",
    "    jitter_x = x + random.randint(-2, 2)\n",
    "    jitter_y = y + random.randint(-2, 2)\n",
    "    await page.mouse.move(jitter_x, jitter_y)\n",
    "    \n",
    "    click_delay = random.randint(80, 200)\n",
    "    await page.mouse.click(jitter_x, jitter_y, delay=click_delay)\n",
    "\n",
    "async def collect_and_save_links(page, click_count, status):\n",
    "    \"\"\"æ”¶é›†å¹¶ä¿å­˜å½“å‰æ‰€æœ‰é“¾æŽ¥åˆ°åŒä¸€ä¸ªæ–‡ä»¶\"\"\"\n",
    "    elements = await page.query_selector_all('a')\n",
    "    urls = set()\n",
    "    for a in elements:\n",
    "        href = await a.get_attribute('href')\n",
    "        if href and href.startswith('/news/articles'):\n",
    "            urls.add(\"https://www.bloomberg.com\" + href)\n",
    "    \n",
    "    data = {\n",
    "        \"last_updated\": time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"clicks_completed\": click_count,\n",
    "        \"total_articles\": len(urls),\n",
    "        \"articles\": sorted(urls)\n",
    "    }\n",
    "    \n",
    "    filename = \"/Users/wangbaihui/bloomberg_econ_links.json\"\n",
    "    with open(filename, \"w\") as f:\n",
    "        json.dump(data, f, indent=2)\n",
    "    \n",
    "\n",
    "    log_progress(status, click_count, len(urls), f\"ðŸ’¾ Saved {len(urls)} articles to {filename}\")\n",
    "    \n",
    "    return len(urls)\n",
    "\n",
    "async def scrape_bloomberg():\n",
    "    status = ScraperStatus()\n",
    "    \n",
    "    try:\n",
    "        async with async_playwright() as p:\n",
    "            log_action(status, \"Launching browser...\", \"Browser Setup\")\n",
    "            \n",
    "            browser = await p.chromium.launch(headless=False)\n",
    "            \n",
    "            context = await browser.new_context(\n",
    "                user_agent=\"Mozilla/5.0 (Macintosh; Intel Mac OS X 13_5_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.6312.122 Safari/537.36\",\n",
    "                viewport={'width': 1280, 'height': 800},\n",
    "                locale='en-US',\n",
    "                timezone_id='America/New_York',\n",
    "                extra_http_headers={\n",
    "                    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',\n",
    "                    'Accept-Language': 'en-US,en;q=0.9',\n",
    "                    'Accept-Encoding': 'gzip, deflate, br',\n",
    "                    'DNT': '1',\n",
    "                    'Upgrade-Insecure-Requests': '1',\n",
    "                    'Sec-Fetch-Dest': 'document',\n",
    "                    'Sec-Fetch-Mode': 'navigate',\n",
    "                    'Sec-Fetch-Site': 'none',\n",
    "                    'Sec-Fetch-User': '?1',\n",
    "                }\n",
    "            )\n",
    "            \n",
    "            await context.add_init_script(\"\"\"\n",
    "                // ç§»é™¤ webdriver å±žæ€§\n",
    "                Object.defineProperty(navigator, 'webdriver', {\n",
    "                    get: () => undefined\n",
    "                });\n",
    "                \n",
    "                // æ¨¡æ‹ŸçœŸå®žçš„æ’ä»¶\n",
    "                Object.defineProperty(navigator, 'plugins', {\n",
    "                    get: () => [1, 2, 3, 4, 5]\n",
    "                });\n",
    "                \n",
    "                // æ¨¡æ‹ŸçœŸå®žçš„è¯­è¨€è®¾ç½®\n",
    "                Object.defineProperty(navigator, 'languages', {\n",
    "                    get: () => ['en-US', 'en']\n",
    "                });\n",
    "                \n",
    "                // è¦†ç›–æƒé™æŸ¥è¯¢\n",
    "                const originalQuery = window.navigator.permissions.query;\n",
    "                window.navigator.permissions.query = (parameters) => (\n",
    "                    parameters.name === 'notifications' ?\n",
    "                        Promise.resolve({ state: Notification.permission }) :\n",
    "                        originalQuery(parameters)\n",
    "                );\n",
    "            \"\"\")\n",
    "            \n",
    "            page = await context.new_page()\n",
    "            \n",
    "            log_action(status, \"Loading Bloomberg Economics page...\", \"Page Loading\")\n",
    "            await page.goto(\"https://www.bloomberg.com/politics\")\n",
    "            await page.wait_for_timeout(random.randint(2000, 3000))  \n",
    "            \n",
    "            log_action(status, \"Quick page exploration...\", \"Initial Exploration\")\n",
    "            \n",
    "            \n",
    "            for initial_round in range(random.randint(1, 2)):  \n",
    "                log_action(status, f\"Initial browsing round {initial_round + 1}\")\n",
    "                await simulate_reading_behavior(page)\n",
    "                await page.wait_for_timeout(random.randint(1000, 2000))  \n",
    "            \n",
    "            log_action(status, \"Getting familiar with page layout...\")\n",
    "            await check_page_sections(page)\n",
    "            await page.wait_for_timeout(random.randint(800, 1500))  \n",
    "            \n",
    "            log_action(status, \"Looking for terms and conditions...\", \"Terms & Conditions\")\n",
    "            try:\n",
    "                accept_button = await page.wait_for_selector('button:has-text(\"Accept\")', timeout=5000)  \n",
    "                if accept_button:\n",
    "                    log_action(status, \"Found Accept button, accepting...\")\n",
    "                    \n",
    "                    await page.wait_for_timeout(random.randint(1000, 2000)) \n",
    "                    \n",
    "                   \n",
    "                    box = await accept_button.bounding_box()\n",
    "                    if box:\n",
    "                        button_x = box['x'] + box['width'] / 2\n",
    "                        button_y = box['y'] + box['height'] / 2\n",
    "                        await human_like_mouse_movement(page, button_x, button_y)\n",
    "                        await page.wait_for_timeout(random.randint(300, 600))  \n",
    "                        \n",
    "                        await perform_human_like_click(page, button_x, button_y)\n",
    "                        await page.wait_for_timeout(random.randint(1000, 2000))  \n",
    "                        log_action(status, \"Terms and conditions accepted\")\n",
    "            except:\n",
    "                log_action(status, \"No Accept button found, continuing...\")\n",
    "            \n",
    "            \n",
    "            log_action(status, \"Starting content exploration...\", \"Content Exploration\")\n",
    "            await simulate_reading_behavior(page)\n",
    "            await page.wait_for_timeout(random.randint(1000, 2000))  \n",
    "            \n",
    "            max_clicks = 300\n",
    "            consecutive_clicks = 0\n",
    "            actual_clicks = 0  \n",
    "            \n",
    "            \n",
    "            log_action(status, \"Collecting initial articles...\", \"Data Collection\")\n",
    "            initial_count = await collect_and_save_links(page, 0, status)\n",
    "            log_action(status, f\"Initial page loaded with {initial_count} articles\")\n",
    "            \n",
    "            \n",
    "            status.update(phase=\"Article Collection\")\n",
    "            for i in range(max_clicks):\n",
    "                try:\n",
    "                    \n",
    "                    log_action(status, f\"Preparing for Load More click {i+1}/{max_clicks}...\")\n",
    "                    status.update(consecutive=consecutive_clicks)\n",
    "                    \n",
    "                    \n",
    "                    if consecutive_clicks >= 2:  \n",
    "                        log_action(status, \"Adding human behavior...\")\n",
    "                        \n",
    "                        \n",
    "                        await simulate_reading_behavior(page)\n",
    "                        await page.wait_for_timeout(random.randint(1000, 2000)) \n",
    "                        \n",
    "                        \n",
    "                        if random.random() < 0.3:  \n",
    "                            action = random.choice(['End', 'PageDown'])  \n",
    "                            log_action(status, f\"Keyboard navigation: {action}\")\n",
    "                            await page.keyboard.press(action)\n",
    "                            await page.wait_for_timeout(random.randint(800, 1500))  \n",
    "                    \n",
    "        \n",
    "                    if consecutive_clicks >= 4:  \n",
    "                        log_action(status, \"Quick exploration...\")\n",
    "                        \n",
    "                        \n",
    "                        exploration = random.choice([\n",
    "                            lambda: page.mouse.wheel(0, random.randint(-400, -200)),\n",
    "                            lambda: quick_scan_page(page),\n",
    "                        ])\n",
    "                        await exploration()\n",
    "                        await page.wait_for_timeout(random.randint(800, 1500)) \n",
    "                    \n",
    "                    \n",
    "                    log_action(status, \"Searching for Load More button...\")\n",
    "                    await page.wait_for_selector('button[aria-label=\"more stories\"]', timeout=10000)  \n",
    "                    button = await page.query_selector('button[aria-label=\"more stories\"]')\n",
    "                    if not button:\n",
    "                        log_action(status, \"No more Load More button found\", \"Completion\")\n",
    "                        break\n",
    "                    \n",
    "                    \n",
    "                    log_action(status, \"Preparing click...\")\n",
    "                    success, x, y = await simulate_human_click_preparation(page, button)\n",
    "                    if not success:\n",
    "                        log_action(status, \"Failed to prepare click \")\n",
    "                        break\n",
    "                    \n",
    "                    \n",
    "                    old_count = len(await page.query_selector_all('section#archive_story_list a'))\n",
    "                    \n",
    "                    \n",
    "                    log_action(status, f\"Clicking Load More {i+1}...\")\n",
    "                    await perform_human_like_click(page, x, y)\n",
    "                    consecutive_clicks += 1\n",
    "                    actual_clicks = i + 1\n",
    "                    \n",
    "                    \n",
    "                    log_action(status, \"Waiting for new content...\")\n",
    "                    try:\n",
    "                        await page.wait_for_function(\n",
    "                            f'document.querySelectorAll(\"section#archive_story_list a\").length > {old_count}',\n",
    "                            timeout=15000 \n",
    "                        )\n",
    "                        log_action(status, \"New content loaded\")\n",
    "                    except:\n",
    "                        log_action(status, \"Timeout waiting for content, continuing...\")\n",
    "                    \n",
    "            \n",
    "                    log_action(status, \"Post-click behavior...\")\n",
    "                    await page.wait_for_timeout(random.randint(800, 1500)) \n",
    "                    \n",
    "                   \n",
    "                    await page.mouse.wheel(0, random.randint(100, 200))\n",
    "                    await page.wait_for_timeout(random.randint(500, 1000))  \n",
    "                    \n",
    "                    \n",
    "                    current_count = await collect_and_save_links(page, actual_clicks, status)\n",
    "                    \n",
    "                    \n",
    "                    if consecutive_clicks >= random.randint(3, 6):  \n",
    "                        log_action(status, f\"Taking break after {consecutive_clicks} clicks...\", \"Rest Period\")\n",
    "                        consecutive_clicks = 0\n",
    "                        \n",
    "                \n",
    "                        break_duration = random.randint(2, 4) \n",
    "                        \n",
    "                        for break_activity in range(break_duration):\n",
    "                            log_action(status, f\"Break activity {break_activity + 1}/{break_duration}\")\n",
    "                            await simulate_reading_behavior(page)\n",
    "                            await page.wait_for_timeout(random.randint(1500, 3000))  \n",
    "                        \n",
    "                        \n",
    "                        if random.random() < 0.2:  \n",
    "                            log_action(status, \"Quick navigation...\")\n",
    "                            await page.keyboard.press('Control+Home')\n",
    "                            await page.wait_for_timeout(random.randint(2000, 4000))  \n",
    "                            await page.keyboard.press('Control+End')\n",
    "                            await page.wait_for_timeout(random.randint(1000, 2000)) \n",
    "                        \n",
    "                        log_action(status, \"Break completed, resuming...\", \"Article Collection\")\n",
    "                        status.update(consecutive=0)\n",
    "                    \n",
    "                    \n",
    "                    await page.wait_for_timeout(random.randint(1500, 3000))\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    log_action(status, f\"Load More click {i+1} failed: {str(e)[:50]}...\")\n",
    "                    await page.screenshot(path=f\"click_error_{i+1}.png\", full_page=True)\n",
    "                    await collect_and_save_links(page, actual_clicks, status)\n",
    "                    break\n",
    "             \n",
    "            log_action(status, \"Creating final summary...\", \"Completion\")\n",
    "            final_count = await collect_and_save_links(page, actual_clicks, status)\n",
    "            log_action(status, f\"Scraping completed! Final: {final_count} articles after {actual_clicks} clicks\")\n",
    "            \n",
    "            await browser.close()\n",
    "            \n",
    "    except KeyboardInterrupt:\n",
    "        log_action(status, \"Scraper stopped by user (Ctrl+C)\", \"User Stopped\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        log_action(status, f\"Unexpected error: {str(e)}\", \"Error\")\n",
    "        return\n",
    "\n",
    "await scrape_bloomberg()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
